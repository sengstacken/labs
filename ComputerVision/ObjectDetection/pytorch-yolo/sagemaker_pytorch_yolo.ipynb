{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f32312b",
   "metadata": {},
   "source": [
    "# Create SageMaker Models Using the PyTorch Model Zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa3bc54",
   "metadata": {},
   "source": [
    "In this example, we use a YOLO object detection model from the Ultralytics to create bounding boxes for pre-defined object classes.\n",
    "\n",
    "This notebook showcases an end-to-end example, from loading the object detection model weights, saving them to an S3 bucket, to writing an entrypoint file and understanding the key parameters in the SageMaker PyTorchModel API. Finally we deploy the model, perform ML model inference, and view the model output and learn how to interpret the results.  Additionally we will add autoscaling to the endpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15e21cf",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b93efc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --upgrade sagemaker\n",
    "%pip install ultralytics\n",
    "%pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7098aca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sagemaker, subprocess, boto3, cv2, time, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sagemaker import s3\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.pytorch import PyTorchPredictor\n",
    "from sagemaker.serializers import DataSerializer\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f41038f",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c6d880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Set a default S3 bucket\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# Get the current AWS region\n",
    "aws_region = boto3.Session().region_name\n",
    "\n",
    "# Get the SageMaker Execution Role\n",
    "role_arn = sagemaker.get_execution_role()\n",
    "\n",
    "BUCKET = os.path.join(\"s3://\", default_bucket)\n",
    "SAGEMAKER_EXECUTION_ROLE_ARN = role_arn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a204c2-9604-4bcc-ac78-bf66c7c511d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2: Loading an ML Model from the artifacts\n",
    "\n",
    "Next we define an object detection model and save the model weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fec9e3-ebfd-4e98-be0d-24f16d4d5eda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Choose a model:\n",
    "model_name = 'yolov8x.pt'\n",
    "\n",
    "yolomodel = YOLO(model_name)\n",
    "bashCommand = f\"tar -cpzf  model.tar.gz {model_name}\"\n",
    "process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()\n",
    "\n",
    "MODEL_ARTIFACTS_FILE_NAME = os.path.join(BUCKET, f\"modelzoo/{model_name.split('.')[0]}/model.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e2a346-2750-4030-9554-814882ab5758",
   "metadata": {},
   "source": [
    "## Step 3: Save and Upload Model Artifacts to S3\n",
    "\n",
    "Since we use Amazon SageMaker for inference, we need to upload the model weights to an S3 bucket. We can do so with the command below, or by downloading and simply dragging and dropping the file directly into S3. We first package the group of files within model.pt to an archive and copy the model weights in `model.tar.gz` from the local machine to the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e479574-cd53-45e2-a549-f795a4e32879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp model.tar.gz $MODEL_ARTIFACTS_FILE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138ae40-4e0a-48c1-a7ff-5e3b630c549c",
   "metadata": {},
   "source": [
    "## Step 4: Building ML Model Inference Scripts\n",
    "Now we go over our entrypoint file `inference.py`. We can deploy a PyTorch model trained outside of SageMaker by using the *PyTorchModel* class. First we construct an `inference.py` entrypoint file to perform inference using SageMaker on sample data hosted in S3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45d38e8-06ce-4d6c-842d-8afc0f8e3fad",
   "metadata": {},
   "source": [
    "Our model artifacts (model checkpoint) referenced by the `model_data` parameter in `PyTorchModel` are loaded from S3 and packaged as part of the SageMaker model docker image. In order to use the trained ML model for serving, we need to instruct the *PyTorchModel* class how to a recover a PyTorch model from the static checkpoint. This deployed endpoint also interacts with REST API calls, we need to tell it how to parse an incoming request to the model. These instructions need to be defined in the entrypoint file.\n",
    "\n",
    "The *entry_point* parameter references a python file named `inference.py`. It defines model loading, input data preprocessing, ML model prediction logic, and output post-processing.\n",
    "\n",
    "`inference.py` contains the following functions. In our example, we implement the `model_fn`, `input_fn`, `predict_fn` and `output_fn` functions to override the default [PyTorch inference handler](https://github.com/aws/sagemaker-pytorch-inference-toolkit/blob/master/src/sagemaker_pytorch_serving_container/default_pytorch_inference_handler.py).\n",
    "\n",
    "1. `model_fn`: Takes in a directory containing static model checkpoints in the inference image. Opens and loads the model from a specified path, and returns a *PyTorch model*.\n",
    "2. `input_fn`: Takes in the payload of the incoming request (*request_body*) and the content type of an upcoming request (*request_content_type*) as input. Handles data decoding. This function that needs to be adjusted for what input the model is expecting\n",
    "3. `predict_fn`: Calls a model on data deserialized in `input_fn`. Perform prediction on the deserialized object, with the loaded model.\n",
    "4. `output_fn`: Serialize the prediction result into the desired response content type. Serializes predictions from `predict_fn` to JSON, CSV or NPY format.\n",
    "\n",
    "The `inference.py` script is used as an input to the Sagemaker deployment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389054f4-6bdb-4978-8ec1-2338de758282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = PyTorchModel(entry_point='inference.py',\n",
    "                     source_dir='./code',\n",
    "                     model_data=MODEL_ARTIFACTS_FILE_NAME, \n",
    "                     framework_version='1.12', \n",
    "                     py_version='py38',\n",
    "                     role=role_arn,\n",
    "                     env={'TS_MAX_RESPONSE_SIZE':'20000000', 'YOLOV8_MODEL': model_name})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c23436f-5843-4f41-af4f-39cc444f8043",
   "metadata": {},
   "source": [
    "## Step 5: Deploy Real Time Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbe92a6-72c0-41f1-a233-25427008381a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INSTANCE_TYPE = 'ml.m5.4xlarge'\n",
    "ENDPOINT_NAME = 'yolov8x-pytorch-' + str(datetime.utcnow().strftime('%Y-%m-%d-%H-%M-%S-%f'))\n",
    "\n",
    "# Store the endpoint name in the history to be accessed by 2_TestEndpoint.ipynb notebook\n",
    "%store ENDPOINT_NAME\n",
    "print(f'Endpoint Name: {ENDPOINT_NAME}')\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1, \n",
    "                         instance_type=INSTANCE_TYPE,\n",
    "                         deserializer=JSONDeserializer(),\n",
    "                         serializer=DataSerializer(content_type=\"image/jpg\"),\n",
    "                         endpoint_name=ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf087b59-a9ae-4297-a804-53e2a725ae7e",
   "metadata": {},
   "source": [
    "## Step 6: Visualizing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199f7004-923d-475b-94b9-a4063f88a9ed",
   "metadata": {},
   "source": [
    "The model outputs bounding boxes with confidence scores. Finally, we visualize these mappings to understand our output in a more meaningful way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ad2540-5661-447a-8b5b-dc9824be7d49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = PyTorchPredictor(endpoint_name=ENDPOINT_NAME,\n",
    "                             deserializer=JSONDeserializer(),\n",
    "                             serializer=DataSerializer(content_type=\"image/jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83de907c-568f-41e5-b53a-325ed8aef010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate color mapping \n",
    "\n",
    "# Dictionary to hold colors for each class\n",
    "class_colors = {}\n",
    "for lbl in yolomodel.names:\n",
    "    # Check if the class color already exists; if not, create it\n",
    "    if lbl not in class_colors:\n",
    "        # Assign a random but consistent color for each class\n",
    "        class_colors[lbl] = (random.randint(10, 255), random.randint(10, 255), random.randint(10, 255))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ae296b-4c10-4b77-8d60-82d77545eb09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "infer_start_time = time.time()\n",
    "\n",
    "orig_image = cv2.imread('cars.jpg')\n",
    "payload = cv2.imencode('.jpg', orig_image)[1].tobytes()\n",
    "results = predictor.predict(payload,)\n",
    "\n",
    "infer_end_time = time.time()\n",
    "\n",
    "print(f\"Inference Time = {infer_end_time - infer_start_time:0.4f} seconds\")\n",
    "\n",
    "for result in results:\n",
    "    box = result[\"box\"]\n",
    "    lbl = result[\"name\"]\n",
    "    classint = result[\"class\"]\n",
    "    conf = result[\"confidence\"]\n",
    "    x1, y1, x2, y2 = int(box[\"x1\"]), int(box[\"y1\"]), int(box[\"x2\"]), int(box[\"y2\"])\n",
    "    color = class_colors[classint]\n",
    "    cv2.rectangle(orig_image, (x1,y1), (x2,y2), color, 4)\n",
    "    cv2.putText(orig_image, f\"Class: {lbl}\", (x1,y1-40), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "    cv2.putText(orig_image, f\"Conf: {int(conf*100)}\", (x1,y1-10), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "    \n",
    "# Create a new figure with specified size\n",
    "plt.figure(figsize=(30, 16))  # You can adjust the size as needed    \n",
    "plt.imshow(cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB))\n",
    "# Turn off the axis\n",
    "plt.axis('off')\n",
    "plt.savefig('result.jpg', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f131ac7-7e96-43af-a843-90e374e196de",
   "metadata": {},
   "source": [
    "## Step 7: Auto Scale the Endpoint!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c953ad1-1d82-4e7b-a9a4-09e76e4b055c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check number of instances on the endpoint\n",
    "bt_sm = boto3.client('sagemaker')\n",
    "response = bt_sm.describe_endpoint(EndpointName=predictor.endpoint_name)\n",
    "print(f\"Endpoint {response['EndpointName']} has \\nCurrent Instance Count: {response['ProductionVariants'][0]['CurrentInstanceCount']}\\nWith a desired instance count of {response['ProductionVariants'][0]['DesiredInstanceCount']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e21a2e6-5fbe-44f8-ac2a-96a6b7c9b4ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"https://console.aws.amazon.com/cloudwatch/home?region={aws_region}#metricsV2:graph=~(metrics~(~(~'AWS*2fSageMaker~'InvocationsPerInstance~'EndpointName~'{predictor.endpoint_name}~'VariantName~'AllTraffic))~view~'timeSeries~stacked~false~region~'{aws_region}~start~'-PT15M~end~'P0D~stat~'SampleCount~period~60);query=~'*7bAWS*2fSageMaker*2cEndpointName*2cVariantName*7d*20{predictor.endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed365cc3-229b-4619-a96a-2967553601df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# application-autoscaling client\n",
    "asg_client = boto3.client(\"application-autoscaling\")\n",
    "\n",
    "# This is the format in which application autoscaling references the endpoint\n",
    "resource_id = f\"endpoint/{predictor.endpoint_name}/variant/AllTraffic\"\n",
    "\n",
    "# Configure Autoscaling on asynchronous endpoint down to zero instances\n",
    "response = asg_client.register_scalable_target(\n",
    "    ServiceNamespace=\"sagemaker\",\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "    MinCapacity=1,\n",
    "    MaxCapacity=3,\n",
    ")\n",
    "\n",
    "response = asg_client.put_scaling_policy(\n",
    "    PolicyName=f'Request-ScalingPolicy-{predictor.endpoint_name}',\n",
    "    ServiceNamespace=\"sagemaker\",\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "    PolicyType=\"TargetTrackingScaling\",\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        'TargetValue': 10.0, # Threshold\n",
    "        'PredefinedMetricSpecification': {\n",
    "            'PredefinedMetricType': 'SageMakerVariantInvocationsPerInstance',\n",
    "        },\n",
    "        'ScaleInCooldown': 300, # duration until scale in\n",
    "        'ScaleOutCooldown': 60 # duration between scale out\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c92b86b-d872-4f08-9d24-ef40b0deb099",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request_duration_in_seconds = 4*65\n",
    "end_time = time.time() + request_duration_in_seconds\n",
    "\n",
    "print(f\"test will run {request_duration_in_seconds} seconds\")\n",
    "\n",
    "orig_image = cv2.imread('cars.jpg')\n",
    "payload = cv2.imencode('.jpg', orig_image)[1].tobytes()\n",
    "\n",
    "while time.time() < end_time:\n",
    "    result = predictor.predict(payload,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b15595-c1b0-440d-9911-cd77e61c3efe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"https://console.aws.amazon.com/cloudwatch/home?region={aws_region}#metricsV2:graph=~(metrics~(~(~'AWS*2fSageMaker~'InvocationsPerInstance~'EndpointName~'{predictor.endpoint_name}~'VariantName~'AllTraffic))~view~'timeSeries~stacked~false~region~'{aws_region}~start~'-PT15M~end~'P0D~stat~'SampleCount~period~60);query=~'*7bAWS*2fSageMaker*2cEndpointName*2cVariantName*7d*20{predictor.endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66933663-c436-43d5-9bcb-01e59910be6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bt_sm = boto3.client('sagemaker')\n",
    "response = bt_sm.describe_endpoint(EndpointName=predictor.endpoint_name)\n",
    "print(f\"Endpoint {response['EndpointName']} has \\nCurrent Instance Count: {response['ProductionVariants'][0]['CurrentInstanceCount']}\\nWith a desired instance count of {response['ProductionVariants'][0]['DesiredInstanceCount']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfe224d-17cc-4000-9dd1-ae6f3de87a5f",
   "metadata": {},
   "source": [
    "## Step 8: Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0767a7-78da-41a8-b715-15bf6f4e5136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = asg_client.deregister_scalable_target(\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d4714-5072-4388-b8be-829df3954994",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4cbd6e",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4f45f4",
   "metadata": {},
   "source": [
    "In this example, we walked through an end-to-end example for performing ML model inference using an object detection model using SageMaker . We covered loading the object detection model weights, saving them to an S3 bucket, writing an entrypoint file and understanding the key parameters in the *PyTorchModel* API. Finally, we deployed the model and performed ML model inference, visualized the model output, and learned how to interpret the results."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "101f88b0feeccf0328ae0dbf08793c07d8b22db8a75cacc2d96d207b00eab69b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
